Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Model Initialized
Starting training epoch 0
Iter: 0 | Loss: 0.7589778304100037 | Accuracy: 0.0
Iter: 100 | Loss: 0.6983238017559051 | Accuracy: 0.22
Iter: 200 | Loss: 0.6087777578830719 | Accuracy: 0.23
Iter: 300 | Loss: 0.5765742176771164 | Accuracy: 0.27
Iter: 400 | Loss: 0.5705218100547791 | Accuracy: 0.26
Iter: 500 | Loss: 0.5698317793011666 | Accuracy: 0.22
Iter: 600 | Loss: 0.5745794108510017 | Accuracy: 0.24
Iter: 700 | Loss: 0.5755291125178337 | Accuracy: 0.26
Iter: 800 | Loss: 0.5728484737873077 | Accuracy: 0.24
Iter: 900 | Loss: 0.573181292116642 | Accuracy: 0.26
Iter: 1000 | Loss: 0.5723668935894967 | Accuracy: 0.23
Iter: 1100 | Loss: 0.5702445867657662 | Accuracy: 0.2
Iter: 1200 | Loss: 0.5702309054136276 | Accuracy: 0.25
Iter: 1300 | Loss: 0.5649966558814049 | Accuracy: 0.25
Iter: 1400 | Loss: 0.5618402767181396 | Accuracy: 0.29
Iter: 1500 | Loss: 0.5641415214538574 | Accuracy: 0.23
Iter: 1600 | Loss: 0.5649709233641624 | Accuracy: 0.25
Iter: 1700 | Loss: 0.564443011879921 | Accuracy: 0.28
Iter: 1800 | Loss: 0.5667173567414284 | Accuracy: 0.26
Iter: 1900 | Loss: 0.561502069234848 | Accuracy: 0.29
Iter: 2000 | Loss: 0.5648123466968537 | Accuracy: 0.27
Iter: 2100 | Loss: 0.5618704849481583 | Accuracy: 0.29
Iter: 2200 | Loss: 0.5615933895111084 | Accuracy: 0.29
Iter: 2300 | Loss: 0.5669196659326553 | Accuracy: 0.25
Iter: 2400 | Loss: 0.5717230960726738 | Accuracy: 0.24
Iter: 2500 | Loss: 0.5676066061854362 | Accuracy: 0.26
Iter: 2600 | Loss: 0.5564124137163162 | Accuracy: 0.36
Iter: 2700 | Loss: 0.554417698085308 | Accuracy: 0.33
Iter: 2800 | Loss: 0.5631763723492622 | Accuracy: 0.31
Iter: 2900 | Loss: 0.5594937336444855 | Accuracy: 0.31
Iter: 3000 | Loss: 0.5729934060573578 | Accuracy: 0.19
Iter: 3100 | Loss: 0.5669026499986649 | Accuracy: 0.22
Iter: 3200 | Loss: 0.5519644784927368 | Accuracy: 0.38
Iter: 3300 | Loss: 0.5656071189045906 | Accuracy: 0.27
Iter: 3400 | Loss: 0.5571994036436081 | Accuracy: 0.34
Iter: 3500 | Loss: 0.5618230408430099 | Accuracy: 0.32
Iter: 3600 | Loss: 0.5594570741057396 | Accuracy: 0.35
Iter: 3700 | Loss: 0.5647227144241334 | Accuracy: 0.28
Iter: 3800 | Loss: 0.5631999361515045 | Accuracy: 0.28
Iter: 3900 | Loss: 0.5669800156354904 | Accuracy: 0.28
Iter: 4000 | Loss: 0.5559071758389473 | Accuracy: 0.36
Iter: 4100 | Loss: 0.562640386223793 | Accuracy: 0.34
Iter: 4200 | Loss: 0.5623400121927261 | Accuracy: 0.33
Iter: 4300 | Loss: 0.5553783151507378 | Accuracy: 0.37
Iter: 4400 | Loss: 0.5565107768774032 | Accuracy: 0.36
Iter: 4500 | Loss: 0.5547286438941955 | Accuracy: 0.36
Iter: 4600 | Loss: 0.5646557512879372 | Accuracy: 0.29
Iter: 4700 | Loss: 0.5580615201592445 | Accuracy: 0.33
Iter: 4800 | Loss: 0.5626328670978546 | Accuracy: 0.28
Iter: 4900 | Loss: 0.5572952237725258 | Accuracy: 0.36
Iter: 4956 | Loss: 0.5634067516241755 | Accuracy: 0.32142857142857145
Validating epoch 0
Saving model...
Epoch: 0 complete | Train Loss: 0.567959725856781 | Train Accuracy: 0.28464797256405083 | Valid Accuracy: 0.404
Starting training epoch 1
Iter: 0 | Loss: 0.5192192196846008 | Accuracy: 1.0
Iter: 100 | Loss: 0.5637839409708977 | Accuracy: 0.27
Iter: 200 | Loss: 0.5638735401630401 | Accuracy: 0.25
Iter: 300 | Loss: 0.5582599899172783 | Accuracy: 0.32
Iter: 400 | Loss: 0.5621548959612847 | Accuracy: 0.24
Iter: 500 | Loss: 0.5638738498091698 | Accuracy: 0.3
Iter: 600 | Loss: 0.5608791530132293 | Accuracy: 0.32
Iter: 700 | Loss: 0.5679815807938575 | Accuracy: 0.26
Iter: 800 | Loss: 0.5631310829520225 | Accuracy: 0.25
Iter: 900 | Loss: 0.5618657296895981 | Accuracy: 0.3
Iter: 1000 | Loss: 0.5656554004549981 | Accuracy: 0.29
Iter: 1100 | Loss: 0.5634785774350166 | Accuracy: 0.28
Iter: 1200 | Loss: 0.5563411629199981 | Accuracy: 0.26
Iter: 1300 | Loss: 0.5552940130233764 | Accuracy: 0.31
Iter: 1400 | Loss: 0.5618594527244568 | Accuracy: 0.29
Iter: 1500 | Loss: 0.5536446389555931 | Accuracy: 0.35
Iter: 1600 | Loss: 0.561208170056343 | Accuracy: 0.32
Iter: 1700 | Loss: 0.5596605196595192 | Accuracy: 0.37
Iter: 1800 | Loss: 0.5620569697022438 | Accuracy: 0.33
Iter: 1900 | Loss: 0.5635500943660736 | Accuracy: 0.26
Iter: 2000 | Loss: 0.5606241092085839 | Accuracy: 0.35
Iter: 2100 | Loss: 0.5604151636362076 | Accuracy: 0.29
Iter: 2200 | Loss: 0.5626033172011375 | Accuracy: 0.29
Iter: 2300 | Loss: 0.5585289931297303 | Accuracy: 0.34
Iter: 2400 | Loss: 0.5619173181056977 | Accuracy: 0.33
Iter: 2500 | Loss: 0.5591689813137054 | Accuracy: 0.29
Iter: 2600 | Loss: 0.5565311959385872 | Accuracy: 0.37
Iter: 2700 | Loss: 0.5567072433233261 | Accuracy: 0.34
Iter: 2800 | Loss: 0.5571295115351677 | Accuracy: 0.32
Iter: 2900 | Loss: 0.558487195968628 | Accuracy: 0.38
Iter: 3000 | Loss: 0.5603164952993392 | Accuracy: 0.32
Iter: 3100 | Loss: 0.561973172724247 | Accuracy: 0.3
Iter: 3200 | Loss: 0.559568644464016 | Accuracy: 0.34
Iter: 3300 | Loss: 0.5622680792212487 | Accuracy: 0.29
Iter: 3400 | Loss: 0.550370392203331 | Accuracy: 0.5
Iter: 3500 | Loss: 0.5557687178254127 | Accuracy: 0.36
Iter: 3600 | Loss: 0.5540418231487274 | Accuracy: 0.36
Iter: 3700 | Loss: 0.5541430935263634 | Accuracy: 0.4
Iter: 3800 | Loss: 0.5575569254159928 | Accuracy: 0.35
Iter: 3900 | Loss: 0.556726468205452 | Accuracy: 0.36
Iter: 4000 | Loss: 0.553037713766098 | Accuracy: 0.34
Iter: 4100 | Loss: 0.5524087849259377 | Accuracy: 0.43
Iter: 4200 | Loss: 0.5567835527658462 | Accuracy: 0.38
Iter: 4300 | Loss: 0.5540014597773552 | Accuracy: 0.42
Iter: 4400 | Loss: 0.5625398594141007 | Accuracy: 0.28
Iter: 4500 | Loss: 0.5567634770274162 | Accuracy: 0.35
Iter: 4600 | Loss: 0.5529844585061073 | Accuracy: 0.37
Iter: 4700 | Loss: 0.5483161008358002 | Accuracy: 0.43
Iter: 4800 | Loss: 0.5589046573638916 | Accuracy: 0.31
Iter: 4900 | Loss: 0.5532231643795967 | Accuracy: 0.44
Iter: 4956 | Loss: 0.5585695313555854 | Accuracy: 0.39285714285714285
Validating epoch 1
Saving model...
Epoch: 1 complete | Train Loss: 0.5588125586509705 | Train Accuracy: 0.33145047407706274 | Valid Accuracy: 0.434
Starting training epoch 2
Iter: 0 | Loss: 0.5453783273696899 | Accuracy: 0.0
Iter: 100 | Loss: 0.5575452437996864 | Accuracy: 0.33
Iter: 200 | Loss: 0.5613781863451004 | Accuracy: 0.3
Iter: 300 | Loss: 0.565378831923008 | Accuracy: 0.21
Iter: 400 | Loss: 0.5580043795704842 | Accuracy: 0.35
Iter: 500 | Loss: 0.5613239896297455 | Accuracy: 0.3
Iter: 600 | Loss: 0.5571182903647423 | Accuracy: 0.33
Iter: 700 | Loss: 0.5588697344064713 | Accuracy: 0.38
Iter: 800 | Loss: 0.5583390235900879 | Accuracy: 0.37
Iter: 900 | Loss: 0.560703461766243 | Accuracy: 0.32
Iter: 1000 | Loss: 0.5596734017133713 | Accuracy: 0.31
Iter: 1100 | Loss: 0.5578182423114777 | Accuracy: 0.3
Iter: 1200 | Loss: 0.5575926554203033 | Accuracy: 0.34
Iter: 1300 | Loss: 0.5563750597834587 | Accuracy: 0.35
Iter: 1400 | Loss: 0.5563685336709022 | Accuracy: 0.39
Iter: 1500 | Loss: 0.5548704665899277 | Accuracy: 0.37
Iter: 1600 | Loss: 0.5494315519928932 | Accuracy: 0.45
Iter: 1700 | Loss: 0.551775712966919 | Accuracy: 0.43
Iter: 1800 | Loss: 0.5623436725139618 | Accuracy: 0.24
Iter: 1900 | Loss: 0.5576658135652542 | Accuracy: 0.35
Iter: 2000 | Loss: 0.5510057738423347 | Accuracy: 0.41
Iter: 2100 | Loss: 0.5574103686213493 | Accuracy: 0.38
Iter: 2200 | Loss: 0.5558448451757431 | Accuracy: 0.41
Iter: 2300 | Loss: 0.5639705100655555 | Accuracy: 0.24
Iter: 2400 | Loss: 0.5631097704172134 | Accuracy: 0.29
Iter: 2500 | Loss: 0.5573351356387138 | Accuracy: 0.33
Iter: 2600 | Loss: 0.5528380888700485 | Accuracy: 0.37
Iter: 2700 | Loss: 0.5542354270815849 | Accuracy: 0.34
Iter: 2800 | Loss: 0.549068221449852 | Accuracy: 0.46
Iter: 2900 | Loss: 0.5499925574660302 | Accuracy: 0.4
Iter: 3000 | Loss: 0.5581176093220711 | Accuracy: 0.29
Iter: 3100 | Loss: 0.5584468093514442 | Accuracy: 0.37
Iter: 3200 | Loss: 0.5533783280849457 | Accuracy: 0.39
Iter: 3300 | Loss: 0.5540442714095115 | Accuracy: 0.35
Iter: 3400 | Loss: 0.5514628651738167 | Accuracy: 0.44
Iter: 3500 | Loss: 0.5521141475439072 | Accuracy: 0.39
Iter: 3600 | Loss: 0.5559265720844269 | Accuracy: 0.33
Iter: 3700 | Loss: 0.5496717694401742 | Accuracy: 0.48
Iter: 3800 | Loss: 0.5532539334893226 | Accuracy: 0.36
Iter: 3900 | Loss: 0.5551352834701538 | Accuracy: 0.42
Iter: 4000 | Loss: 0.5482595312595367 | Accuracy: 0.41
Iter: 4100 | Loss: 0.5595643800497055 | Accuracy: 0.37
Iter: 4200 | Loss: 0.560664775967598 | Accuracy: 0.26
Iter: 4300 | Loss: 0.5515082776546478 | Accuracy: 0.42
Iter: 4400 | Loss: 0.5531024798750878 | Accuracy: 0.36
Iter: 4500 | Loss: 0.5533500117063522 | Accuracy: 0.34
Iter: 4600 | Loss: 0.5511867478489876 | Accuracy: 0.4
Iter: 4700 | Loss: 0.5512119227647782 | Accuracy: 0.42
Iter: 4800 | Loss: 0.5486101013422012 | Accuracy: 0.45
Iter: 4900 | Loss: 0.5598148348927497 | Accuracy: 0.33
Iter: 4956 | Loss: 0.5442923977971077 | Accuracy: 0.5357142857142857
Validating epoch 2
Saving model...
Epoch: 2 complete | Train Loss: 0.5557090640068054 | Train Accuracy: 0.3617107121242687 | Valid Accuracy: 0.442
Starting training epoch 3
Iter: 0 | Loss: 0.4897952675819397 | Accuracy: 1.0
Iter: 100 | Loss: 0.5587859711050988 | Accuracy: 0.36
Iter: 200 | Loss: 0.5584858936071396 | Accuracy: 0.34
Iter: 300 | Loss: 0.5608525821566581 | Accuracy: 0.33
Iter: 400 | Loss: 0.5660378408432006 | Accuracy: 0.29
Iter: 500 | Loss: 0.5594822725653649 | Accuracy: 0.29
Iter: 600 | Loss: 0.5554087436199189 | Accuracy: 0.36
Iter: 700 | Loss: 0.5571185904741287 | Accuracy: 0.39
Iter: 800 | Loss: 0.5574208825826645 | Accuracy: 0.37
Iter: 900 | Loss: 0.5594977936148644 | Accuracy: 0.36
Iter: 1000 | Loss: 0.560994240641594 | Accuracy: 0.26
Iter: 1100 | Loss: 0.5573127362132072 | Accuracy: 0.34
Iter: 1200 | Loss: 0.5584857258200645 | Accuracy: 0.42
Iter: 1300 | Loss: 0.5518948751688003 | Accuracy: 0.43
Iter: 1400 | Loss: 0.5520399504899979 | Accuracy: 0.37
Iter: 1500 | Loss: 0.5518214890360832 | Accuracy: 0.4
Iter: 1600 | Loss: 0.5485022872686386 | Accuracy: 0.41
Iter: 1700 | Loss: 0.554054394364357 | Accuracy: 0.43
Iter: 1800 | Loss: 0.5522530066967011 | Accuracy: 0.38
Iter: 1900 | Loss: 0.5507681345939637 | Accuracy: 0.4
Iter: 2000 | Loss: 0.5471918532252311 | Accuracy: 0.44
Iter: 2100 | Loss: 0.5578681111335755 | Accuracy: 0.37
Iter: 2200 | Loss: 0.560455017387867 | Accuracy: 0.26
Iter: 2300 | Loss: 0.5546807634830475 | Accuracy: 0.41
Iter: 2400 | Loss: 0.5600870516896248 | Accuracy: 0.32
Iter: 2500 | Loss: 0.5591476511955261 | Accuracy: 0.39
Iter: 2600 | Loss: 0.5477725511789322 | Accuracy: 0.43
Iter: 2700 | Loss: 0.5508822277188301 | Accuracy: 0.46
Iter: 2800 | Loss: 0.5459993928670883 | Accuracy: 0.46
Iter: 2900 | Loss: 0.5552337044477462 | Accuracy: 0.41
Iter: 3000 | Loss: 0.5524983590841294 | Accuracy: 0.48
Iter: 3100 | Loss: 0.5467343112826347 | Accuracy: 0.46
Iter: 3200 | Loss: 0.5526506119966507 | Accuracy: 0.38
Iter: 3300 | Loss: 0.5513588917255402 | Accuracy: 0.38
Iter: 3400 | Loss: 0.5454004752635956 | Accuracy: 0.47
Iter: 3500 | Loss: 0.5489420396089554 | Accuracy: 0.34
Iter: 3600 | Loss: 0.5445611193776131 | Accuracy: 0.5
Iter: 3700 | Loss: 0.5486616906523705 | Accuracy: 0.44
Iter: 3800 | Loss: 0.5504188567399979 | Accuracy: 0.37
Iter: 3900 | Loss: 0.5474199262261391 | Accuracy: 0.44
Iter: 4000 | Loss: 0.5491470250487328 | Accuracy: 0.46
Iter: 4100 | Loss: 0.5519414046406745 | Accuracy: 0.4
Iter: 4200 | Loss: 0.5578306052088737 | Accuracy: 0.32
Iter: 4300 | Loss: 0.5414492672681809 | Accuracy: 0.54
Iter: 4400 | Loss: 0.5548408231139184 | Accuracy: 0.42
Iter: 4500 | Loss: 0.554725063443184 | Accuracy: 0.35
Iter: 4600 | Loss: 0.5541620472073555 | Accuracy: 0.4
Iter: 4700 | Loss: 0.5496834111213684 | Accuracy: 0.47
Iter: 4800 | Loss: 0.5526127180457115 | Accuracy: 0.41
Iter: 4900 | Loss: 0.5476226162910461 | Accuracy: 0.41
Iter: 4956 | Loss: 0.5423748466585364 | Accuracy: 0.5
Validating epoch 3
Epoch: 3 complete | Train Loss: 0.5531930327415466 | Train Accuracy: 0.3956021787371394 | Valid Accuracy: 0.438
Starting training epoch 4
Iter: 0 | Loss: 0.5326582789421082 | Accuracy: 0.0
Iter: 100 | Loss: 0.5587067273259163 | Accuracy: 0.36
Iter: 200 | Loss: 0.5551217150688171 | Accuracy: 0.42
Iter: 300 | Loss: 0.5557749244570732 | Accuracy: 0.43
Iter: 400 | Loss: 0.5618749457597733 | Accuracy: 0.25
Iter: 500 | Loss: 0.5607300728559494 | Accuracy: 0.32
Iter: 600 | Loss: 0.5547144144773484 | Accuracy: 0.36
Iter: 700 | Loss: 0.5545500701665879 | Accuracy: 0.4
Iter: 800 | Loss: 0.5553891804814338 | Accuracy: 0.37
Iter: 900 | Loss: 0.5607181736826896 | Accuracy: 0.33
Iter: 1000 | Loss: 0.5501910209655761 | Accuracy: 0.43
Iter: 1100 | Loss: 0.5603297454118729 | Accuracy: 0.31
Iter: 1200 | Loss: 0.5555727314949036 | Accuracy: 0.41
Iter: 1300 | Loss: 0.5502494075894355 | Accuracy: 0.37
Iter: 1400 | Loss: 0.5528508624434472 | Accuracy: 0.4
Iter: 1500 | Loss: 0.5512626802921295 | Accuracy: 0.41
Iter: 1600 | Loss: 0.5472993510961532 | Accuracy: 0.47
Iter: 1700 | Loss: 0.5480683374404908 | Accuracy: 0.43
Iter: 1800 | Loss: 0.5437210100889206 | Accuracy: 0.5
Iter: 1900 | Loss: 0.550295697748661 | Accuracy: 0.41
Iter: 2000 | Loss: 0.547533032298088 | Accuracy: 0.38
Iter: 2100 | Loss: 0.552581507563591 | Accuracy: 0.39
Iter: 2200 | Loss: 0.5486468952894211 | Accuracy: 0.48
Iter: 2300 | Loss: 0.559484845995903 | Accuracy: 0.34
Iter: 2400 | Loss: 0.56024857878685 | Accuracy: 0.37
Iter: 2500 | Loss: 0.5507038477063179 | Accuracy: 0.39
Iter: 2600 | Loss: 0.5510541865229607 | Accuracy: 0.44
Iter: 2700 | Loss: 0.550953713953495 | Accuracy: 0.46
Iter: 2800 | Loss: 0.5519920107722283 | Accuracy: 0.37
Iter: 2900 | Loss: 0.5520268765091896 | Accuracy: 0.39
Iter: 3000 | Loss: 0.5544896590709686 | Accuracy: 0.41
Iter: 3100 | Loss: 0.554526235461235 | Accuracy: 0.36
Iter: 3200 | Loss: 0.5513437458872795 | Accuracy: 0.33
Iter: 3300 | Loss: 0.5521449160575866 | Accuracy: 0.41
Iter: 3400 | Loss: 0.5474201682209968 | Accuracy: 0.43
Iter: 3500 | Loss: 0.5520308613777161 | Accuracy: 0.43
Iter: 3600 | Loss: 0.5480126681923866 | Accuracy: 0.43
Iter: 3700 | Loss: 0.5452411550283432 | Accuracy: 0.46
Iter: 3800 | Loss: 0.5480372241139412 | Accuracy: 0.41
Iter: 3900 | Loss: 0.5510018700361252 | Accuracy: 0.37
Iter: 4000 | Loss: 0.5421673262119293 | Accuracy: 0.49
Iter: 4100 | Loss: 0.5448949691653252 | Accuracy: 0.51
Iter: 4200 | Loss: 0.5538649603724479 | Accuracy: 0.32
Iter: 4300 | Loss: 0.544556880891323 | Accuracy: 0.47
Iter: 4400 | Loss: 0.5586117136478425 | Accuracy: 0.3
Iter: 4500 | Loss: 0.5537801226973533 | Accuracy: 0.36
Iter: 4600 | Loss: 0.5474056068062783 | Accuracy: 0.43
Iter: 4700 | Loss: 0.5465425843000412 | Accuracy: 0.46
Iter: 4800 | Loss: 0.5494805213809013 | Accuracy: 0.47
Iter: 4900 | Loss: 0.5539890217781067 | Accuracy: 0.4
Iter: 4956 | Loss: 0.5335755103400776 | Accuracy: 0.6071428571428571
Validating epoch 4
Epoch: 4 complete | Train Loss: 0.5518726110458374 | Train Accuracy: 0.40306637078878355 | Valid Accuracy: 0.424
Starting training epoch 5
Iter: 0 | Loss: 0.5549925565719604 | Accuracy: 0.0
Iter: 100 | Loss: 0.5528070664405823 | Accuracy: 0.39
Iter: 200 | Loss: 0.5602873519062996 | Accuracy: 0.3
Iter: 300 | Loss: 0.5595045840740204 | Accuracy: 0.33
Iter: 400 | Loss: 0.5590919885039329 | Accuracy: 0.38
Iter: 500 | Loss: 0.561630426645279 | Accuracy: 0.24
Iter: 600 | Loss: 0.5484728345274925 | Accuracy: 0.47
Iter: 700 | Loss: 0.5589987468719483 | Accuracy: 0.31
Iter: 800 | Loss: 0.5532508087158203 | Accuracy: 0.42
Iter: 900 | Loss: 0.5641071525216103 | Accuracy: 0.32
Iter: 1000 | Loss: 0.5523624789714813 | Accuracy: 0.41
Iter: 1100 | Loss: 0.554967284500599 | Accuracy: 0.34
Iter: 1200 | Loss: 0.5504042223095894 | Accuracy: 0.41
Iter: 1300 | Loss: 0.5505392727255821 | Accuracy: 0.42
Iter: 1400 | Loss: 0.5509059005975723 | Accuracy: 0.4
Iter: 1500 | Loss: 0.5557079949975013 | Accuracy: 0.4
Iter: 1600 | Loss: 0.5476733207702636 | Accuracy: 0.41
Iter: 1700 | Loss: 0.5429302024841308 | Accuracy: 0.48
Iter: 1800 | Loss: 0.5511029055714607 | Accuracy: 0.33
Iter: 1900 | Loss: 0.5488359272480011 | Accuracy: 0.44
Iter: 2000 | Loss: 0.5490578770637512 | Accuracy: 0.42
Iter: 2100 | Loss: 0.5509180039167404 | Accuracy: 0.41
Iter: 2200 | Loss: 0.5564511469006539 | Accuracy: 0.33
Iter: 2300 | Loss: 0.5497427639365197 | Accuracy: 0.43
Iter: 2400 | Loss: 0.5561001986265183 | Accuracy: 0.36
Iter: 2500 | Loss: 0.5513886186480522 | Accuracy: 0.42
Iter: 2600 | Loss: 0.5475635612010956 | Accuracy: 0.38
Iter: 2700 | Loss: 0.5538284480571747 | Accuracy: 0.41
Iter: 2800 | Loss: 0.551759121119976 | Accuracy: 0.38
Iter: 2900 | Loss: 0.5476078855991363 | Accuracy: 0.45
Iter: 3000 | Loss: 0.5497751078009605 | Accuracy: 0.41
Iter: 3100 | Loss: 0.5506924200057983 | Accuracy: 0.38
Iter: 3200 | Loss: 0.5528379252552986 | Accuracy: 0.43
Iter: 3300 | Loss: 0.5512585514783859 | Accuracy: 0.43
Iter: 3400 | Loss: 0.5457221683859825 | Accuracy: 0.37
Iter: 3500 | Loss: 0.5508521819114685 | Accuracy: 0.34
Iter: 3600 | Loss: 0.5472520276904106 | Accuracy: 0.45
Iter: 3700 | Loss: 0.5414446172118187 | Accuracy: 0.43
Iter: 3800 | Loss: 0.5412073495984078 | Accuracy: 0.53
Iter: 3900 | Loss: 0.547806724011898 | Accuracy: 0.44
Iter: 4000 | Loss: 0.5466574883460998 | Accuracy: 0.42
Iter: 4100 | Loss: 0.5498778736591339 | Accuracy: 0.42
Iter: 4200 | Loss: 0.5508080986142159 | Accuracy: 0.39
Iter: 4300 | Loss: 0.5493138113617897 | Accuracy: 0.49
Iter: 4400 | Loss: 0.5497773453593254 | Accuracy: 0.36
Iter: 4500 | Loss: 0.5531527119874954 | Accuracy: 0.35
Iter: 4600 | Loss: 0.550120579302311 | Accuracy: 0.42
Iter: 4700 | Loss: 0.5429792216420174 | Accuracy: 0.45
Iter: 4800 | Loss: 0.5508752486109734 | Accuracy: 0.42
Iter: 4900 | Loss: 0.5467871755361557 | Accuracy: 0.46
Iter: 4956 | Loss: 0.5360185871166843 | Accuracy: 0.5357142857142857
Validating epoch 5
Saving model...
Epoch: 5 complete | Train Loss: 0.5509968996047974 | Train Accuracy: 0.4010490215856365 | Valid Accuracy: 0.448
Starting training epoch 6
Iter: 0 | Loss: 0.5066361427307129 | Accuracy: 1.0
Iter: 100 | Loss: 0.5593402463197709 | Accuracy: 0.38
Iter: 200 | Loss: 0.5605262976884842 | Accuracy: 0.3
Iter: 300 | Loss: 0.5612821733951568 | Accuracy: 0.35
Iter: 400 | Loss: 0.5534427201747895 | Accuracy: 0.35
Iter: 500 | Loss: 0.5622444856166839 | Accuracy: 0.37
Iter: 600 | Loss: 0.5578815788030624 | Accuracy: 0.39
Iter: 700 | Loss: 0.5608106273412704 | Accuracy: 0.3
Iter: 800 | Loss: 0.5500607496500015 | Accuracy: 0.37
Iter: 900 | Loss: 0.5625115182995796 | Accuracy: 0.3
Iter: 1000 | Loss: 0.5544497472047806 | Accuracy: 0.36
Iter: 1100 | Loss: 0.55632647305727 | Accuracy: 0.38
Iter: 1200 | Loss: 0.5524563112854958 | Accuracy: 0.39
Iter: 1300 | Loss: 0.5519078943133354 | Accuracy: 0.35
Iter: 1400 | Loss: 0.5504087260365487 | Accuracy: 0.44
Iter: 1500 | Loss: 0.5479218992590904 | Accuracy: 0.4
Iter: 1600 | Loss: 0.5458421564102173 | Accuracy: 0.42
Iter: 1700 | Loss: 0.5458305677771569 | Accuracy: 0.41
Iter: 1800 | Loss: 0.5504405173659325 | Accuracy: 0.41
Iter: 1900 | Loss: 0.5546851825714111 | Accuracy: 0.4
Iter: 2000 | Loss: 0.5478099602460861 | Accuracy: 0.43
Iter: 2100 | Loss: 0.554221311211586 | Accuracy: 0.39
Iter: 2200 | Loss: 0.5490045383572578 | Accuracy: 0.43
Iter: 2300 | Loss: 0.5490058016777039 | Accuracy: 0.45
Iter: 2400 | Loss: 0.5543705329298974 | Accuracy: 0.47
Iter: 2500 | Loss: 0.5541952750086785 | Accuracy: 0.36
Iter: 2600 | Loss: 0.5489387971162796 | Accuracy: 0.45
Iter: 2700 | Loss: 0.5499605405330658 | Accuracy: 0.44
Iter: 2800 | Loss: 0.5462882152199745 | Accuracy: 0.38
Iter: 2900 | Loss: 0.5441992491483688 | Accuracy: 0.5
Iter: 3000 | Loss: 0.5508143770694732 | Accuracy: 0.33
Iter: 3100 | Loss: 0.5495239016413689 | Accuracy: 0.43
Iter: 3200 | Loss: 0.5491715955734253 | Accuracy: 0.4
Iter: 3300 | Loss: 0.5526619657874108 | Accuracy: 0.4
Iter: 3400 | Loss: 0.5433177545666694 | Accuracy: 0.48
Iter: 3500 | Loss: 0.549844044148922 | Accuracy: 0.34
Iter: 3600 | Loss: 0.5481387513875962 | Accuracy: 0.44
Iter: 3700 | Loss: 0.5482948142290115 | Accuracy: 0.39
Iter: 3800 | Loss: 0.5479559093713761 | Accuracy: 0.39
Iter: 3900 | Loss: 0.5445548883080482 | Accuracy: 0.43
Iter: 4000 | Loss: 0.5454900592565537 | Accuracy: 0.43
Iter: 4100 | Loss: 0.5451078262925148 | Accuracy: 0.44
Iter: 4200 | Loss: 0.5546938648819923 | Accuracy: 0.39
Iter: 4300 | Loss: 0.5451298689842224 | Accuracy: 0.44
Iter: 4400 | Loss: 0.5534200626611709 | Accuracy: 0.36
Iter: 4500 | Loss: 0.5438170477747917 | Accuracy: 0.42
Iter: 4600 | Loss: 0.5379030373692513 | Accuracy: 0.56
Iter: 4700 | Loss: 0.5439769423007965 | Accuracy: 0.45
Iter: 4800 | Loss: 0.5463111430406571 | Accuracy: 0.45
Iter: 4900 | Loss: 0.5452243277430534 | Accuracy: 0.47
Iter: 4956 | Loss: 0.539214950054884 | Accuracy: 0.5
Validating epoch 6
Saving model...
Epoch: 6 complete | Train Loss: 0.5505095720291138 | Train Accuracy: 0.40548718983256 | Valid Accuracy: 0.452
Starting training epoch 7
Iter: 0 | Loss: 0.5426671504974365 | Accuracy: 1.0
Iter: 100 | Loss: 0.55253159314394 | Accuracy: 0.38
Iter: 200 | Loss: 0.5533907815814019 | Accuracy: 0.36
Iter: 300 | Loss: 0.5587905353307724 | Accuracy: 0.3
Iter: 400 | Loss: 0.547894107401371 | Accuracy: 0.46
Iter: 500 | Loss: 0.5596887287497521 | Accuracy: 0.3
Iter: 600 | Loss: 0.5523182469606399 | Accuracy: 0.41
Iter: 700 | Loss: 0.5612643107771873 | Accuracy: 0.32
Iter: 800 | Loss: 0.555779612660408 | Accuracy: 0.33
Iter: 900 | Loss: 0.5581169047951698 | Accuracy: 0.42
Iter: 1000 | Loss: 0.5550961920619011 | Accuracy: 0.35
Iter: 1100 | Loss: 0.5572602346539497 | Accuracy: 0.36
Iter: 1200 | Loss: 0.5543226790428162 | Accuracy: 0.34
Iter: 1300 | Loss: 0.5469112688302994 | Accuracy: 0.44
Iter: 1400 | Loss: 0.5520633181929588 | Accuracy: 0.37
Iter: 1500 | Loss: 0.5524721908569336 | Accuracy: 0.36
Iter: 1600 | Loss: 0.5451494672894478 | Accuracy: 0.46
Iter: 1700 | Loss: 0.5442472344636917 | Accuracy: 0.47
Iter: 1800 | Loss: 0.5526052388548851 | Accuracy: 0.34
Iter: 1900 | Loss: 0.5454485261440277 | Accuracy: 0.45
Iter: 2000 | Loss: 0.5510436281561851 | Accuracy: 0.42
Iter: 2100 | Loss: 0.5514644199609756 | Accuracy: 0.37
Iter: 2200 | Loss: 0.5468153461813927 | Accuracy: 0.44
Iter: 2300 | Loss: 0.550941978096962 | Accuracy: 0.42
Iter: 2400 | Loss: 0.5598060578107834 | Accuracy: 0.4
Iter: 2500 | Loss: 0.5475702431797981 | Accuracy: 0.48
Iter: 2600 | Loss: 0.5486859303712844 | Accuracy: 0.44
Iter: 2700 | Loss: 0.5483845108747483 | Accuracy: 0.39
Iter: 2800 | Loss: 0.5445482885837555 | Accuracy: 0.42
Iter: 2900 | Loss: 0.5479918935894966 | Accuracy: 0.39
Iter: 3000 | Loss: 0.543423957824707 | Accuracy: 0.49
Iter: 3100 | Loss: 0.5517681059241295 | Accuracy: 0.43
Iter: 3200 | Loss: 0.5442223268747329 | Accuracy: 0.46
Iter: 3300 | Loss: 0.5460937741398811 | Accuracy: 0.46
Iter: 3400 | Loss: 0.547587668299675 | Accuracy: 0.45
Iter: 3500 | Loss: 0.5462982133030891 | Accuracy: 0.5
Iter: 3600 | Loss: 0.5437259736657143 | Accuracy: 0.49
Iter: 3700 | Loss: 0.5308020606637001 | Accuracy: 0.53
Iter: 3800 | Loss: 0.5510336914658547 | Accuracy: 0.42
Iter: 3900 | Loss: 0.5433079442381858 | Accuracy: 0.47
Iter: 4000 | Loss: 0.5479836824536324 | Accuracy: 0.38
Iter: 4100 | Loss: 0.5414949131011962 | Accuracy: 0.46
Iter: 4200 | Loss: 0.5498677885532379 | Accuracy: 0.4
Iter: 4300 | Loss: 0.5378978189826011 | Accuracy: 0.46
Iter: 4400 | Loss: 0.551784333884716 | Accuracy: 0.34
Iter: 4500 | Loss: 0.5498242336511612 | Accuracy: 0.44
Iter: 4600 | Loss: 0.5425777840614319 | Accuracy: 0.45
Iter: 4700 | Loss: 0.5416175803542137 | Accuracy: 0.41
Iter: 4800 | Loss: 0.5436686557531357 | Accuracy: 0.47
Iter: 4900 | Loss: 0.5374173414707184 | Accuracy: 0.48
Iter: 4956 | Loss: 0.5310572013258934 | Accuracy: 0.5
Validating epoch 7
Saving model...
Epoch: 7 complete | Train Loss: 0.5486751198768616 | Train Accuracy: 0.4169860802904983 | Valid Accuracy: 0.458
Starting training epoch 8
Iter: 0 | Loss: 0.5573035478591919 | Accuracy: 0.0
Iter: 100 | Loss: 0.5485576152801513 | Accuracy: 0.43
Iter: 200 | Loss: 0.5549417927861213 | Accuracy: 0.34
Iter: 300 | Loss: 0.5612280282378197 | Accuracy: 0.32
Iter: 400 | Loss: 0.5535858607292176 | Accuracy: 0.37
Iter: 500 | Loss: 0.5591015645861626 | Accuracy: 0.34
Iter: 600 | Loss: 0.5605838876962662 | Accuracy: 0.3
Iter: 700 | Loss: 0.5507339951395989 | Accuracy: 0.34
Iter: 800 | Loss: 0.5561514404416085 | Accuracy: 0.37
Iter: 900 | Loss: 0.5607492446899414 | Accuracy: 0.33
Iter: 1000 | Loss: 0.546527256667614 | Accuracy: 0.42
Iter: 1100 | Loss: 0.5552231603860855 | Accuracy: 0.36
Iter: 1200 | Loss: 0.5501044955849648 | Accuracy: 0.47
Iter: 1300 | Loss: 0.5479628130793571 | Accuracy: 0.46
Iter: 1400 | Loss: 0.54961840569973 | Accuracy: 0.39
Iter: 1500 | Loss: 0.551007927954197 | Accuracy: 0.41
Iter: 1600 | Loss: 0.5444667196273804 | Accuracy: 0.44
Iter: 1700 | Loss: 0.538843734562397 | Accuracy: 0.47
Iter: 1800 | Loss: 0.5569861316680909 | Accuracy: 0.34
Iter: 1900 | Loss: 0.5435470899939537 | Accuracy: 0.41
Iter: 2000 | Loss: 0.5456347644329071 | Accuracy: 0.46
Iter: 2100 | Loss: 0.5528998354077339 | Accuracy: 0.4
Iter: 2200 | Loss: 0.5501934742927551 | Accuracy: 0.44
Iter: 2300 | Loss: 0.5515423601865769 | Accuracy: 0.41
Iter: 2400 | Loss: 0.5559071660041809 | Accuracy: 0.38
Iter: 2500 | Loss: 0.5483793687820434 | Accuracy: 0.4
Iter: 2600 | Loss: 0.5422907376289368 | Accuracy: 0.48
Iter: 2700 | Loss: 0.5501688852906227 | Accuracy: 0.42
Iter: 2800 | Loss: 0.5450933781266213 | Accuracy: 0.42
Iter: 2900 | Loss: 0.5446097207069397 | Accuracy: 0.5
Iter: 3000 | Loss: 0.5554543581604957 | Accuracy: 0.33
Iter: 3100 | Loss: 0.5507328119874001 | Accuracy: 0.37
Iter: 3200 | Loss: 0.5487987527251244 | Accuracy: 0.37
Iter: 3300 | Loss: 0.5491659545898437 | Accuracy: 0.35
Iter: 3400 | Loss: 0.5430463320016861 | Accuracy: 0.48
Iter: 3500 | Loss: 0.5486179944872857 | Accuracy: 0.41
Iter: 3600 | Loss: 0.5438552668690682 | Accuracy: 0.45
Iter: 3700 | Loss: 0.53721190482378 | Accuracy: 0.5
Iter: 3800 | Loss: 0.5465080377459526 | Accuracy: 0.41
Iter: 3900 | Loss: 0.5486504700779915 | Accuracy: 0.39
Iter: 4000 | Loss: 0.5462273854017258 | Accuracy: 0.43
Iter: 4100 | Loss: 0.5416286876797676 | Accuracy: 0.48
Iter: 4200 | Loss: 0.550981921851635 | Accuracy: 0.46
Iter: 4300 | Loss: 0.5509806808829307 | Accuracy: 0.38
Iter: 4400 | Loss: 0.5410619542002678 | Accuracy: 0.43
Iter: 4500 | Loss: 0.5458228251338005 | Accuracy: 0.44
Iter: 4600 | Loss: 0.5385235130786896 | Accuracy: 0.44
Iter: 4700 | Loss: 0.5353945314884185 | Accuracy: 0.5
Iter: 4800 | Loss: 0.5485330188274383 | Accuracy: 0.41
Iter: 4900 | Loss: 0.5423975762724876 | Accuracy: 0.45
Iter: 4956 | Loss: 0.5321014906678881 | Accuracy: 0.5357142857142857
Validating epoch 8
Saving model...
Epoch: 8 complete | Train Loss: 0.5485933423042297 | Train Accuracy: 0.4115392374420012 | Valid Accuracy: 0.462
Starting training epoch 9
Iter: 0 | Loss: 0.4825955927371979 | Accuracy: 1.0
Iter: 100 | Loss: 0.5462094122171401 | Accuracy: 0.42
Iter: 200 | Loss: 0.555200492143631 | Accuracy: 0.38
Iter: 300 | Loss: 0.5534938776493072 | Accuracy: 0.36
Iter: 400 | Loss: 0.5507566493749618 | Accuracy: 0.45
Iter: 500 | Loss: 0.5540835478901863 | Accuracy: 0.39
Iter: 600 | Loss: 0.558468852341175 | Accuracy: 0.31
Iter: 700 | Loss: 0.5635482084751129 | Accuracy: 0.3
Iter: 800 | Loss: 0.5496481323242187 | Accuracy: 0.43
Iter: 900 | Loss: 0.5621001026034356 | Accuracy: 0.31
Iter: 1000 | Loss: 0.5479022541642189 | Accuracy: 0.43
Iter: 1100 | Loss: 0.5529664742946625 | Accuracy: 0.41
Iter: 1200 | Loss: 0.5505473744869233 | Accuracy: 0.39
Iter: 1300 | Loss: 0.5443523982167244 | Accuracy: 0.43
Iter: 1400 | Loss: 0.55285765260458 | Accuracy: 0.39
Iter: 1500 | Loss: 0.5482769605517387 | Accuracy: 0.36
Iter: 1600 | Loss: 0.5440664571523667 | Accuracy: 0.46
Iter: 1700 | Loss: 0.5446774262189865 | Accuracy: 0.47
Iter: 1800 | Loss: 0.5444533038139343 | Accuracy: 0.43
Iter: 1900 | Loss: 0.5448186340928077 | Accuracy: 0.42
Iter: 2000 | Loss: 0.5369883641600609 | Accuracy: 0.53
Iter: 2100 | Loss: 0.557920347750187 | Accuracy: 0.35
Iter: 2200 | Loss: 0.549384676516056 | Accuracy: 0.45
Iter: 2300 | Loss: 0.5522334244847298 | Accuracy: 0.34
Iter: 2400 | Loss: 0.5576583462953567 | Accuracy: 0.37
Iter: 2500 | Loss: 0.5462332651019096 | Accuracy: 0.47
Iter: 2600 | Loss: 0.5502821916341781 | Accuracy: 0.46
Iter: 2700 | Loss: 0.5501574325561523 | Accuracy: 0.46
Iter: 2800 | Loss: 0.5416883796453476 | Accuracy: 0.46
Iter: 2900 | Loss: 0.5428980350494385 | Accuracy: 0.47
Iter: 3000 | Loss: 0.5429692566394806 | Accuracy: 0.42
Iter: 3100 | Loss: 0.5450098204612732 | Accuracy: 0.44
Iter: 3200 | Loss: 0.5491075798869133 | Accuracy: 0.41
Iter: 3300 | Loss: 0.5407205620408058 | Accuracy: 0.43
Iter: 3400 | Loss: 0.5390591007471085 | Accuracy: 0.48
Iter: 3500 | Loss: 0.5507923218607903 | Accuracy: 0.39
Iter: 3600 | Loss: 0.540170581638813 | Accuracy: 0.43
Iter: 3700 | Loss: 0.5329014360904694 | Accuracy: 0.5
Iter: 3800 | Loss: 0.5411110138893127 | Accuracy: 0.44
Iter: 3900 | Loss: 0.5457705464959145 | Accuracy: 0.46
Iter: 4000 | Loss: 0.5399781662225723 | Accuracy: 0.45
Iter: 4100 | Loss: 0.5422692769765853 | Accuracy: 0.47
Iter: 4200 | Loss: 0.5491560626029969 | Accuracy: 0.43
Iter: 4300 | Loss: 0.5368905475735665 | Accuracy: 0.46
Iter: 4400 | Loss: 0.5489945581555367 | Accuracy: 0.4
Iter: 4500 | Loss: 0.5437158420681953 | Accuracy: 0.41
Iter: 4600 | Loss: 0.5438900345563888 | Accuracy: 0.48
Iter: 4700 | Loss: 0.5421945869922637 | Accuracy: 0.45
Iter: 4800 | Loss: 0.5385838735103607 | Accuracy: 0.53
Iter: 4900 | Loss: 0.5455639094114304 | Accuracy: 0.43
Iter: 4956 | Loss: 0.5449111945927143 | Accuracy: 0.48214285714285715
Validating epoch 9
Saving model...
Epoch: 9 complete | Train Loss: 0.5471595525741577 | Train Accuracy: 0.42545894694371594 | Valid Accuracy: 0.464
Starting training epoch 10
Iter: 0 | Loss: 0.5055956840515137 | Accuracy: 1.0
Iter: 100 | Loss: 0.55075269728899 | Accuracy: 0.35
Iter: 200 | Loss: 0.5529353812336921 | Accuracy: 0.35
Iter: 300 | Loss: 0.556389711201191 | Accuracy: 0.32
Iter: 400 | Loss: 0.559057147204876 | Accuracy: 0.31
Iter: 500 | Loss: 0.5592816871404648 | Accuracy: 0.33
Iter: 600 | Loss: 0.5568362590670586 | Accuracy: 0.35
Iter: 700 | Loss: 0.5539738523960114 | Accuracy: 0.35
Iter: 800 | Loss: 0.5517605167627334 | Accuracy: 0.38
Iter: 900 | Loss: 0.5568047145009041 | Accuracy: 0.38
Iter: 1000 | Loss: 0.5555632677674294 | Accuracy: 0.36
Iter: 1100 | Loss: 0.552162710428238 | Accuracy: 0.39
Iter: 1200 | Loss: 0.5478170132637024 | Accuracy: 0.41
Iter: 1300 | Loss: 0.5477527126669883 | Accuracy: 0.4
Iter: 1400 | Loss: 0.5510830357670784 | Accuracy: 0.45
Iter: 1500 | Loss: 0.5560124412178993 | Accuracy: 0.38
Iter: 1600 | Loss: 0.5358781909942627 | Accuracy: 0.47
Iter: 1700 | Loss: 0.5406595477461815 | Accuracy: 0.52
Iter: 1800 | Loss: 0.5609722810983658 | Accuracy: 0.31
Iter: 1900 | Loss: 0.5443390902876853 | Accuracy: 0.43
Iter: 2000 | Loss: 0.5464628538489342 | Accuracy: 0.41
Iter: 2100 | Loss: 0.5437888169288635 | Accuracy: 0.45
Iter: 2200 | Loss: 0.5388839218020439 | Accuracy: 0.48
Iter: 2300 | Loss: 0.550847969353199 | Accuracy: 0.49
Iter: 2400 | Loss: 0.5579676720499992 | Accuracy: 0.39
Iter: 2500 | Loss: 0.5522095996141434 | Accuracy: 0.44
Iter: 2600 | Loss: 0.544227747619152 | Accuracy: 0.44
Iter: 2700 | Loss: 0.5440646573901177 | Accuracy: 0.46
Iter: 2800 | Loss: 0.5470483449101448 | Accuracy: 0.38
Iter: 2900 | Loss: 0.5495095312595367 | Accuracy: 0.46
Iter: 3000 | Loss: 0.538351233303547 | Accuracy: 0.55
Iter: 3100 | Loss: 0.5495331159234047 | Accuracy: 0.38
Iter: 3200 | Loss: 0.5414771911501884 | Accuracy: 0.5
Iter: 3300 | Loss: 0.5463919529318809 | Accuracy: 0.39
Iter: 3400 | Loss: 0.5416470298171043 | Accuracy: 0.4
Iter: 3500 | Loss: 0.550377930700779 | Accuracy: 0.35
Iter: 3600 | Loss: 0.5370507010817528 | Accuracy: 0.49
Iter: 3700 | Loss: 0.5344149929285049 | Accuracy: 0.5
Iter: 3800 | Loss: 0.551591078042984 | Accuracy: 0.36
Iter: 3900 | Loss: 0.5495825478434563 | Accuracy: 0.41
Iter: 4000 | Loss: 0.5338036313652992 | Accuracy: 0.55
Iter: 4100 | Loss: 0.5430376735329628 | Accuracy: 0.41
Iter: 4200 | Loss: 0.5426739946007728 | Accuracy: 0.49
Iter: 4300 | Loss: 0.5366950541734695 | Accuracy: 0.5
Iter: 4400 | Loss: 0.5393099051713943 | Accuracy: 0.47
Iter: 4500 | Loss: 0.5407133609056473 | Accuracy: 0.45
Iter: 4600 | Loss: 0.5391916501522064 | Accuracy: 0.55
Iter: 4700 | Loss: 0.5360370522737503 | Accuracy: 0.46
Iter: 4800 | Loss: 0.5419776228070259 | Accuracy: 0.48
Iter: 4900 | Loss: 0.5449292278289795 | Accuracy: 0.46
Iter: 4956 | Loss: 0.5257834957114288 | Accuracy: 0.5
Validating epoch 10
Saving model...
Epoch: 10 complete | Train Loss: 0.5467672348022461 | Train Accuracy: 0.4252572120234013 | Valid Accuracy: 0.466
Starting training epoch 11
Iter: 0 | Loss: 0.48982706665992737 | Accuracy: 1.0
Iter: 100 | Loss: 0.5527252933382988 | Accuracy: 0.36
Iter: 200 | Loss: 0.5581465414166451 | Accuracy: 0.38
Iter: 300 | Loss: 0.5598858338594437 | Accuracy: 0.33
Iter: 400 | Loss: 0.5465537667274475 | Accuracy: 0.44
Iter: 500 | Loss: 0.5494277650117874 | Accuracy: 0.44
Iter: 600 | Loss: 0.5528103125095367 | Accuracy: 0.41
Iter: 700 | Loss: 0.5562470492720604 | Accuracy: 0.4
Iter: 800 | Loss: 0.5503164300322533 | Accuracy: 0.36
Iter: 900 | Loss: 0.5580344098806381 | Accuracy: 0.31
Iter: 1000 | Loss: 0.5427158322930336 | Accuracy: 0.47
Iter: 1100 | Loss: 0.5585865345597267 | Accuracy: 0.36
Iter: 1200 | Loss: 0.5594066178798676 | Accuracy: 0.36
Iter: 1300 | Loss: 0.5472149232029915 | Accuracy: 0.45
Iter: 1400 | Loss: 0.5487976735830307 | Accuracy: 0.39
Iter: 1500 | Loss: 0.5468720138072968 | Accuracy: 0.42
Iter: 1600 | Loss: 0.5362621438503266 | Accuracy: 0.44
Iter: 1700 | Loss: 0.5481572553515435 | Accuracy: 0.44
Iter: 1800 | Loss: 0.5459275677800178 | Accuracy: 0.47
Iter: 1900 | Loss: 0.5464084780216217 | Accuracy: 0.41
Iter: 2000 | Loss: 0.5319625017046928 | Accuracy: 0.58
Iter: 2100 | Loss: 0.5448638674616814 | Accuracy: 0.45
Iter: 2200 | Loss: 0.545663230419159 | Accuracy: 0.46
Iter: 2300 | Loss: 0.5529664081335067 | Accuracy: 0.41
Iter: 2400 | Loss: 0.5505410584807396 | Accuracy: 0.4
Iter: 2500 | Loss: 0.5446641287207603 | Accuracy: 0.47
Iter: 2600 | Loss: 0.5477347204089165 | Accuracy: 0.4
Iter: 2700 | Loss: 0.5566585144400596 | Accuracy: 0.34
Iter: 2800 | Loss: 0.5513177245855332 | Accuracy: 0.42
Iter: 2900 | Loss: 0.5407173132896423 | Accuracy: 0.48
Iter: 3000 | Loss: 0.5419435331225395 | Accuracy: 0.45
Iter: 3100 | Loss: 0.5465831303596497 | Accuracy: 0.39
Iter: 3200 | Loss: 0.5457331505417824 | Accuracy: 0.41
Iter: 3300 | Loss: 0.541328184902668 | Accuracy: 0.53
Iter: 3400 | Loss: 0.5391172450780869 | Accuracy: 0.46
Iter: 3500 | Loss: 0.5361889332532883 | Accuracy: 0.52
Iter: 3600 | Loss: 0.5390757668018341 | Accuracy: 0.47
Iter: 3700 | Loss: 0.5273091739416123 | Accuracy: 0.53
Iter: 3800 | Loss: 0.5416003221273422 | Accuracy: 0.46
Iter: 3900 | Loss: 0.5406511172652244 | Accuracy: 0.55
Iter: 4000 | Loss: 0.5381206500530243 | Accuracy: 0.5
Iter: 4100 | Loss: 0.54876738011837 | Accuracy: 0.46
Iter: 4200 | Loss: 0.5500140181183815 | Accuracy: 0.41
Iter: 4300 | Loss: 0.5388298001885414 | Accuracy: 0.47
Iter: 4400 | Loss: 0.5383472144603729 | Accuracy: 0.47
Iter: 4500 | Loss: 0.5463264292478561 | Accuracy: 0.48
Iter: 4600 | Loss: 0.5366407623887062 | Accuracy: 0.54
Iter: 4700 | Loss: 0.5352904179692268 | Accuracy: 0.49
Iter: 4800 | Loss: 0.5494544398784638 | Accuracy: 0.44
Iter: 4900 | Loss: 0.5368316060304642 | Accuracy: 0.48
Iter: 4956 | Loss: 0.5163581158433642 | Accuracy: 0.6428571428571429
Validating epoch 11
Epoch: 11 complete | Train Loss: 0.5455676317214966 | Train Accuracy: 0.4424046802501513 | Valid Accuracy: 0.466
Starting training epoch 12
Iter: 0 | Loss: 0.49063897132873535 | Accuracy: 1.0
Iter: 100 | Loss: 0.5585716128349304 | Accuracy: 0.33
Iter: 200 | Loss: 0.5598427134752274 | Accuracy: 0.37
Iter: 300 | Loss: 0.5620368966460227 | Accuracy: 0.33
Iter: 400 | Loss: 0.5526622503995895 | Accuracy: 0.33
Iter: 500 | Loss: 0.556449171602726 | Accuracy: 0.36
Iter: 600 | Loss: 0.5536717346310616 | Accuracy: 0.43
Iter: 700 | Loss: 0.5497782406210899 | Accuracy: 0.37
Iter: 800 | Loss: 0.5472119736671448 | Accuracy: 0.44
Iter: 900 | Loss: 0.5558283773064613 | Accuracy: 0.38
Iter: 1000 | Loss: 0.5489139512181282 | Accuracy: 0.44
Iter: 1100 | Loss: 0.5529348143935203 | Accuracy: 0.41
Iter: 1200 | Loss: 0.545377177298069 | Accuracy: 0.5
Iter: 1300 | Loss: 0.5488980764150619 | Accuracy: 0.37
Iter: 1400 | Loss: 0.5416580444574356 | Accuracy: 0.48
Iter: 1500 | Loss: 0.5390772148966789 | Accuracy: 0.47
Iter: 1600 | Loss: 0.5451100066304206 | Accuracy: 0.39
Iter: 1700 | Loss: 0.5461427995562553 | Accuracy: 0.45
Iter: 1800 | Loss: 0.5431570175290108 | Accuracy: 0.4
Iter: 1900 | Loss: 0.5539599967002868 | Accuracy: 0.33
Iter: 2000 | Loss: 0.5429871854186058 | Accuracy: 0.41
Iter: 2100 | Loss: 0.5490365245938301 | Accuracy: 0.43
Iter: 2200 | Loss: 0.5433075937628746 | Accuracy: 0.51
Iter: 2300 | Loss: 0.5609321138262748 | Accuracy: 0.32
Iter: 2400 | Loss: 0.5546553260087967 | Accuracy: 0.37
Iter: 2500 | Loss: 0.5505847090482712 | Accuracy: 0.4
Iter: 2600 | Loss: 0.5436816430091858 | Accuracy: 0.42
Iter: 2700 | Loss: 0.5442698529362678 | Accuracy: 0.46
Iter: 2800 | Loss: 0.5440688273310661 | Accuracy: 0.39
Iter: 2900 | Loss: 0.5399031388759613 | Accuracy: 0.45
Iter: 3000 | Loss: 0.5441500926017762 | Accuracy: 0.49
Iter: 3100 | Loss: 0.5395734596252442 | Accuracy: 0.48
Iter: 3200 | Loss: 0.5430062183737755 | Accuracy: 0.41
Iter: 3300 | Loss: 0.5455415013432503 | Accuracy: 0.41
Iter: 3400 | Loss: 0.5425371140241623 | Accuracy: 0.4
Iter: 3500 | Loss: 0.5480768823623657 | Accuracy: 0.41
Iter: 3600 | Loss: 0.5414381745457649 | Accuracy: 0.46
Iter: 3700 | Loss: 0.535419011414051 | Accuracy: 0.5
Iter: 3800 | Loss: 0.5500693923234939 | Accuracy: 0.39
Iter: 3900 | Loss: 0.5452630257606507 | Accuracy: 0.44
Iter: 4000 | Loss: 0.5399809992313385 | Accuracy: 0.49
Iter: 4100 | Loss: 0.5496142163872719 | Accuracy: 0.4
Iter: 4200 | Loss: 0.5420388862490654 | Accuracy: 0.47
Iter: 4300 | Loss: 0.5412860736250877 | Accuracy: 0.45
Iter: 4400 | Loss: 0.5424921381473541 | Accuracy: 0.47
Iter: 4500 | Loss: 0.5429119327664376 | Accuracy: 0.42
Iter: 4600 | Loss: 0.541991736292839 | Accuracy: 0.46
Iter: 4700 | Loss: 0.5444879135489464 | Accuracy: 0.5
Iter: 4800 | Loss: 0.5438768655061722 | Accuracy: 0.48
Iter: 4900 | Loss: 0.5345997306704521 | Accuracy: 0.51
Iter: 4956 | Loss: 0.5173560955694744 | Accuracy: 0.5892857142857143
Validating epoch 12
Saving model...
Epoch: 12 complete | Train Loss: 0.5464537739753723 | Train Accuracy: 0.42606415170466005 | Valid Accuracy: 0.478
Starting training epoch 13
Iter: 0 | Loss: 0.4765414595603943 | Accuracy: 1.0
Iter: 100 | Loss: 0.5469971105456353 | Accuracy: 0.34
Iter: 200 | Loss: 0.5523106908798218 | Accuracy: 0.33
Iter: 300 | Loss: 0.562646490931511 | Accuracy: 0.31
Iter: 400 | Loss: 0.5518703043460846 | Accuracy: 0.39
Iter: 500 | Loss: 0.5605110034346581 | Accuracy: 0.31
Iter: 600 | Loss: 0.5524170345067978 | Accuracy: 0.36
Iter: 700 | Loss: 0.5621302822232246 | Accuracy: 0.31
Iter: 800 | Loss: 0.5507099744677544 | Accuracy: 0.43
Iter: 900 | Loss: 0.5562040883302689 | Accuracy: 0.36
Iter: 1000 | Loss: 0.5505198806524276 | Accuracy: 0.29
Iter: 1100 | Loss: 0.551598336994648 | Accuracy: 0.39
Iter: 1200 | Loss: 0.545987763106823 | Accuracy: 0.41
Iter: 1300 | Loss: 0.5448252871632576 | Accuracy: 0.44
Iter: 1400 | Loss: 0.5392798107862472 | Accuracy: 0.44
Iter: 1500 | Loss: 0.5468340420722961 | Accuracy: 0.42
Iter: 1600 | Loss: 0.5401404219865799 | Accuracy: 0.45
Iter: 1700 | Loss: 0.5384792390465737 | Accuracy: 0.47
Iter: 1800 | Loss: 0.5447674390673637 | Accuracy: 0.46
Iter: 1900 | Loss: 0.5386758485436439 | Accuracy: 0.47
Iter: 2000 | Loss: 0.5494480997323989 | Accuracy: 0.41
Iter: 2100 | Loss: 0.5523976704478264 | Accuracy: 0.39
Iter: 2200 | Loss: 0.548639811873436 | Accuracy: 0.41
Iter: 2300 | Loss: 0.5522302603721618 | Accuracy: 0.43
Iter: 2400 | Loss: 0.5500117200613022 | Accuracy: 0.43
Iter: 2500 | Loss: 0.5483164662122726 | Accuracy: 0.41
Iter: 2600 | Loss: 0.5436153018474579 | Accuracy: 0.45
Iter: 2700 | Loss: 0.5467389577627182 | Accuracy: 0.5
Iter: 2800 | Loss: 0.5508303213119506 | Accuracy: 0.44
Iter: 2900 | Loss: 0.5419907790422439 | Accuracy: 0.46
Iter: 3000 | Loss: 0.5430148383975029 | Accuracy: 0.47
Iter: 3100 | Loss: 0.5457026594877243 | Accuracy: 0.38
Iter: 3200 | Loss: 0.5474181669950485 | Accuracy: 0.36
Iter: 3300 | Loss: 0.5424234628677368 | Accuracy: 0.47
Iter: 3400 | Loss: 0.5386874270439148 | Accuracy: 0.44
Iter: 3500 | Loss: 0.5449386608600616 | Accuracy: 0.41
Iter: 3600 | Loss: 0.5362977343797684 | Accuracy: 0.5
Iter: 3700 | Loss: 0.5293580004572869 | Accuracy: 0.58
Iter: 3800 | Loss: 0.5367902025580407 | Accuracy: 0.51
Iter: 3900 | Loss: 0.5458640006184577 | Accuracy: 0.38
Iter: 4000 | Loss: 0.5343689307570457 | Accuracy: 0.44
Iter: 4100 | Loss: 0.5454931902885437 | Accuracy: 0.53
Iter: 4200 | Loss: 0.5516795244812965 | Accuracy: 0.45
Iter: 4300 | Loss: 0.5492170643806458 | Accuracy: 0.37
Iter: 4400 | Loss: 0.5466385370492935 | Accuracy: 0.37
Iter: 4500 | Loss: 0.5381530785560608 | Accuracy: 0.51
Iter: 4600 | Loss: 0.5289586067199707 | Accuracy: 0.58
Iter: 4700 | Loss: 0.5349821424484253 | Accuracy: 0.45
Iter: 4800 | Loss: 0.5508587527275085 | Accuracy: 0.41
Iter: 4900 | Loss: 0.5317182376980781 | Accuracy: 0.47
Iter: 4956 | Loss: 0.5391364512698991 | Accuracy: 0.44642857142857145
Validating epoch 13
Saving model...
Epoch: 13 complete | Train Loss: 0.5457016229629517 | Train Accuracy: 0.4246520072624571 | Valid Accuracy: 0.48
Starting training epoch 14
Iter: 0 | Loss: 0.4436587691307068 | Accuracy: 1.0
Iter: 100 | Loss: 0.5500475570559502 | Accuracy: 0.35
Iter: 200 | Loss: 0.5509266889095307 | Accuracy: 0.42
Iter: 300 | Loss: 0.5571432295441627 | Accuracy: 0.3
Iter: 400 | Loss: 0.5523055225610733 | Accuracy: 0.41
Iter: 500 | Loss: 0.5490360695123673 | Accuracy: 0.45
Iter: 600 | Loss: 0.5521746954321861 | Accuracy: 0.37
Iter: 700 | Loss: 0.5606435480713844 | Accuracy: 0.28
Iter: 800 | Loss: 0.5556208443641663 | Accuracy: 0.33
Iter: 900 | Loss: 0.5566129297018051 | Accuracy: 0.36
Iter: 1000 | Loss: 0.5394963178038598 | Accuracy: 0.46
Iter: 1100 | Loss: 0.5517773219943046 | Accuracy: 0.36
Iter: 1200 | Loss: 0.5476985409855842 | Accuracy: 0.34
Iter: 1300 | Loss: 0.5452792561054229 | Accuracy: 0.44
Iter: 1400 | Loss: 0.5476942503452301 | Accuracy: 0.41
Iter: 1500 | Loss: 0.5470473673939705 | Accuracy: 0.47
Iter: 1600 | Loss: 0.5372707623243332 | Accuracy: 0.45
Iter: 1700 | Loss: 0.5470547565817833 | Accuracy: 0.44
Iter: 1800 | Loss: 0.5499465534090996 | Accuracy: 0.42
Iter: 1900 | Loss: 0.5453210946917534 | Accuracy: 0.39
Iter: 2000 | Loss: 0.5551736786961555 | Accuracy: 0.38
Iter: 2100 | Loss: 0.5481139683723449 | Accuracy: 0.43
Iter: 2200 | Loss: 0.5459921151399613 | Accuracy: 0.42
Iter: 2300 | Loss: 0.5526246079802513 | Accuracy: 0.36
Iter: 2400 | Loss: 0.5544269615411759 | Accuracy: 0.42
Iter: 2500 | Loss: 0.5444098147749901 | Accuracy: 0.49
Iter: 2600 | Loss: 0.546822150349617 | Accuracy: 0.44
Iter: 2700 | Loss: 0.548128767311573 | Accuracy: 0.45
Iter: 2800 | Loss: 0.5482059901952744 | Accuracy: 0.36
Iter: 2900 | Loss: 0.5479542616009713 | Accuracy: 0.39
Iter: 3000 | Loss: 0.5400180172920227 | Accuracy: 0.56
Iter: 3100 | Loss: 0.5444176828861237 | Accuracy: 0.4
Iter: 3200 | Loss: 0.54473468542099 | Accuracy: 0.42
Iter: 3300 | Loss: 0.5466713866591454 | Accuracy: 0.39
Iter: 3400 | Loss: 0.5399078947305679 | Accuracy: 0.52
Iter: 3500 | Loss: 0.5466503846645355 | Accuracy: 0.4
Iter: 3600 | Loss: 0.5309343430399894 | Accuracy: 0.54
Iter: 3700 | Loss: 0.5240485355257988 | Accuracy: 0.55
Iter: 3800 | Loss: 0.5393026474118233 | Accuracy: 0.38
Iter: 3900 | Loss: 0.540578655898571 | Accuracy: 0.45
Iter: 4000 | Loss: 0.5437910386919975 | Accuracy: 0.4
Iter: 4100 | Loss: 0.5433673828840255 | Accuracy: 0.47
Iter: 4200 | Loss: 0.5408553349971771 | Accuracy: 0.5
Iter: 4300 | Loss: 0.535380392074585 | Accuracy: 0.53
Iter: 4400 | Loss: 0.5421161490678787 | Accuracy: 0.42
Iter: 4500 | Loss: 0.5401483869552612 | Accuracy: 0.53
Iter: 4600 | Loss: 0.5355384144186973 | Accuracy: 0.58
Iter: 4700 | Loss: 0.538667279779911 | Accuracy: 0.43
Iter: 4800 | Loss: 0.5496617841720581 | Accuracy: 0.5
Iter: 4900 | Loss: 0.5363070538640022 | Accuracy: 0.46
Iter: 4956 | Loss: 0.530450278627021 | Accuracy: 0.6071428571428571
Validating epoch 14
Epoch: 14 complete | Train Loss: 0.5454823970794678 | Train Accuracy: 0.4311075247125277 | Valid Accuracy: 0.466
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
0.458
